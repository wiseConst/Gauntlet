#version 460

#extension GL_KHR_vulkan_glsl : enable

layout(location = 0) in vec2 in_UV;

layout(location = 0) out float out_FragColor;

layout(set = 0, binding = 0) uniform sampler2D u_PositionMap;
layout(set = 0, binding = 1) uniform sampler2D u_NormalMap;
layout(set = 0, binding = 2) uniform sampler2D u_TexNoiseMap;

layout(set = 0, binding = 3) uniform UBSSAO
{
	mat4 CameraProjection;
	mat4 InvViewMatrix;
	float Radius;
	float Bias;
	int Magnitude;
} u_UBSSAO;

vec2 GetNoiseUV()
{
	const ivec2 texDim   = textureSize(u_PositionMap, 0);
	const ivec2 noiseDim = textureSize(u_TexNoiseMap, 0);
	return vec2(float(texDim.x) / float(noiseDim.x), float(texDim.y) / float(noiseDim.y)) * in_UV;
}

// Pregenerated by me samples that are in TBN space
const int maxSamplesNum = 16;
const vec3 samples[maxSamplesNum] = {
        vec3(0.0503445,0.0217214,0.0641986),vec3(0.00837404,0.0667834,0.05623),
        vec3(0.0224165,0.0189854,0.0325471),vec3(0.00594137,-0.00307045,0.00331808),
        vec3(-0.0159512,-0.0311123,0.0659393),vec3(0.00516041,0.055751,0.070698),
        vec3(0.154211,-0.0388485,0.102913),vec3(-0.163676,-0.0644617,0.0140806),
        vec3(0.289096,-0.114518,0.00878639),vec3(0.191679,-0.186311,0.201556),
        vec3(0.188451,-0.0166253,0.308235),vec3(0.27503,0.0200761,0.226216),
        vec3(0.18431,0.290627,0.0778982),vec3(0.518095,0.0435445,0.0835122),
        vec3(-0.0664,-0.306636,0.20302),vec3(0.411915,-0.471147,0.198689)
};

void main()
{
	const vec3 worldPos = texture(u_PositionMap, in_UV).xyz;
	const vec3 worldN = normalize(texture(u_NormalMap, in_UV)).xyz;

	// Random rotation vector along Z axis in tangent space
	const vec3 randomVec = normalize(texture(u_TexNoiseMap, GetNoiseUV()).xyz);

	// TBN change-of-basis from tanget space -> world space (since normal in world)
	const vec3 T = normalize(randomVec - worldN * dot(randomVec, worldN)); // gram-schmidt orthogonalization(projecting randomVec onto worldN and making it perpendicular)
	const vec3 B = cross(worldN, T);
	const mat3 TBN = mat3(T, B, worldN);
	
	float occlusion = 0.0f;
	for(int i = 0; i < maxSamplesNum; ++i)
	{
	    vec3 samplePos = TBN * samples[i];
	    samplePos = worldPos + samplePos * u_UBSSAO.Radius;

		const vec3 sampleDir = normalize(samplePos - worldPos); // world space sample direction
        const float NdotS = max(dot(worldN, sampleDir), 0); // to make sure that the angle between normal and sample direction is not obtuse(>90 degrees)
		if(NdotS < 0.15) continue; // also if sampleDir is almost parallel it sucks

		samplePos = vec3(u_UBSSAO.InvViewMatrix * vec4(samplePos, 1.0f)); // transform sample from world to view space

		vec4 offsetUV = vec4(samplePos, 1.0f);
		offsetUV      = u_UBSSAO.CameraProjection * offsetUV;   // view -> clip ([-w,w])
		offsetUV.xy = (offsetUV.xy / offsetUV.w) * 0.5f + 0.5f; // clip -> [-1, 1] (ndc) -> UV space
		offsetUV.y *= -1.0F;

		// To make sure that distance between sampled pos and init pos in a hemisphere radius range
		const vec4 worldOffsetPos = texture(u_PositionMap, offsetUV.xy);
		const float rangeCheck = smoothstep(0.0, 1.0, u_UBSSAO.Radius / abs(worldPos.z -  worldOffsetPos.z));
		
		const vec3 renderedFragmentViewPos = vec3(u_UBSSAO.InvViewMatrix * worldOffsetPos); // transform offset pos from world to view space
		occlusion += (renderedFragmentViewPos.z >= samplePos.z + u_UBSSAO.Bias ? 1.0f : 0.0f) * NdotS * rangeCheck; // in case rendered fragment is further than generated sample, then sample is not occluded
	}
	occlusion = 1.0f - (occlusion / (float(maxSamplesNum))); // subtract 1.0f(since 0 means occlusion, and 1 not) from mapped occlusion in range from [0, NUM_SAMPLES] to [0, 1]
	out_FragColor = pow(occlusion, u_UBSSAO.Magnitude); 
}